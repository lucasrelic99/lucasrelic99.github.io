<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Lucas Relic</title>

    <meta name="author" content="Lucas Relic">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Lucas Relic
                </p>
                <p>
                  I'm currently a PhD student at <a href="https://inf.ethz.ch">ETH Z&uuml;rich</a>, advised by <a href="https://inf.ethz.ch/de/personen/person-detail.mgross.html">Markus Gross</a>. My PhD is part of a joint program between the <a href="https://cgl.ethz.ch">Computer Graphics Laboratory</a> and <a href="https://studios.disneyresearch.com">Disney Research|Studios</a>. I work on learning-based methods for data compression.
                </p>
                <p>
                  I'm interested in applied research of deep learning and generative AI to domains such as data compression and computer graphics. My current research is about using generative models as a strong prior for data compression, particularly at extremely low bitrates. I previously worked in computational neuroscience, focusing on improving the quality of prosthetic vision.
                </p>
                <p>
                  Earlier, I earned my B.S. and M.S. at <a href="https://cs.ucsb.edu/">UCSB</a> in computer engineering and computer science, respectively.
                </p>
                <p style="text-align:center">
                  <a href="mailto:lucas.relic99@gmail.com">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/LucasRelic-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=ARrpwnQAAAAJ">Google Scholar</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/LucasRelic.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/LucasRelic.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <!-- Template -->
            <!-- <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
                  <source src="images/r2r.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/r2r.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function r2r_start() {
                    document.getElementById('r2r_image').style.opacity = "1";
                  }

                  function r2r_stop() {
                    document.getElementById('r2r_image').style.opacity = "0";
                  }
                  r2r_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://relight-to-reconstruct.github.io/">
                  <span class="papertitle">Generative Multiview Relighting for 3D Reconstruction under Extreme Illumination Variation</span>
                </a>
                <br>
                <a href="https://hadizayer.github.io/">Hadi Alzayer</a>,
                <a href="https://henzler.github.io/">Philipp Henzler</a>,
                <strong>Jonathan T. Barron</strong>, 
                <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>,
                <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>, 
                <a href="https://dorverbin.github.io/">Dor Verbin</a>
                <br>
                <em>arXiv</em>, 2024 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://relight-to-reconstruct.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2412.15211">arXiv</a>
                <p></p>
                <p>
                Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
                </p>
              </td>
            </tr> -->


          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <img src='images/papers/uddq.png' width=100%>
              </div>
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=wqN6rWwYsr">
                <span class="papertitle">Bridging the Gap between Gaussian Diffusion Models and
                  Universal Quantization for Image Compression</span>
              </a>
              <br>
              <strong>Lucas Relic</strong>,
              Roberto Azevedo,
              Yang Zhang,
              Markus Gross,
              Christopher Schroers
              <br>
              <em>to appear in CVPR</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2504.02579">arXiv</a>
              <br>
              <em>initial version presented at Machine Learning and Compression Workshop @ NeurIPS</em>, 2024
              <br>
              <a href="https://cgl.ethz.ch/disclaimer.php?dlurl=/Downloads/Publications/Papers/2024/Rel24b/Rel24b.pdf">paper</a>
              <p></p>
              <p>
              We developed a quanitzation-based diffusion forward process and a uniform noise diffusion model, which improves compression performance at extremely low bitrates.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <img src='images/papers/ddq.png' width=100%>
              </div>
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-031-73030-6_17">
                <span class="papertitle">Lossy Image Compression with Foundation Diffusion Models</span>
              </a>
              <br>
              <strong>Lucas Relic</strong>,
              Roberto Azevedo,
              Markus Gross,
              Christopher Schroers
              <br>
              <em>ECCV</em>, 2024
              <br>
              <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07844.pdf">paper</a>
              /
              <a href="https://arxiv.org/abs/2404.08580">arXiv</a>
              <p></p>
              <p>
              Foundation diffusion models can be built into an image codec by using them to "undo" quantization error.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <img src='images/papers/vcformer.png' width=100%>
              </div>
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3581783.3611960">
                <span class="papertitle">Neural Video Compression with Spatio-temporal Cross-covariance Transformers</span>
              </a>
              <br>
              Zhenghao Chen,
              <strong>Lucas Relic</strong>,
              Roberto Azevedo,
              Yang Zhang,
              Markus Gross,
              Dong Xu,
              Luping Zhou,
              Christopher Schroers
              <br>
              <em>ACM Multimedia</em>, 2023
              <br>
              <a href="https://assets.studios.disneyresearch.com/app/uploads/2023/09/Neural-Video-Compression-with-Spatio-Temporal-Cross-Covariance-Transformers-Paper.pdf">paper</a>
              /
              <a href="data/citations/vcformer.html">BibTeX</a>
              <p></p>
              <p>
              We developed a novel transformer block to better capture spatio-temporal dependencies between frames in neural video compression.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <img src='images/papers/hna.png' width=100%>
              </div>
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/8e9a6582caa59fda0302349702965171-Abstract-Conference.html">
                <span class="papertitle">Hybrid Neural Autoencoders for Stimulus Encoding in Visual and Other Sensory Neuroprostheses</span>
              </a>
              <br>
              Jacob Granley,
              <strong>Lucas Relic</strong>,
              Michael Beyeler
              <br>
              <em>NeurIPS</em>, 2022
              <br>
              <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/8e9a6582caa59fda0302349702965171-Paper-Conference.pdf">paper</a>
              /
              <a href="https://arxiv.org/abs/2205.13623">arXiv</a>
              /
              <a href="data/citations/hna.html">BibTeX</a>
              <p></p>
              <p>
              By using a differentiable model of the human retina within an autoencoder, we optimized input stimuli for retinal implants (or any neuroprosthesis with a differentiable computational model).
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <div class="one">
                <img src='images/papers/pse.png' width=100%>
              </div>
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3519391.3524034">
                <span class="papertitle">Deep Learning-Based Perceptual Stimulus Encoder for Bionic Visions</span>
              </a>
              <br>
              <strong>Lucas Relic</strong>,
              Bowen Zhang,
              Yi-Lin Tuan,
              Michael Beyeler
              <br>
              <em>ACM Augmented Humans</em>, 2022 &nbsp <font color="red"><strong>(Best Poster Award)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2203.05604">arXiv</a>
              /
              <a href="data/citations/pse.html">BibTeX</a>
              <p></p>
              <p>
              We optimized the input to visual prosthetics using a neural approximation of a human retinal model.
              </p>
            </td>
          </tr>

          </tbody></table>

          
					<!-- <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a>
								<br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023</a>
								<br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a>
								<br>
								<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a>
								<br>
								<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table> -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website design from <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
